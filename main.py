#!/usr/bin/env python
# -*- coding: utf-8 -*-

import csv
import os
import re
import json
import sys
import argparse
from enum import Enum
import spacy
from transliterate import translit

# –ü—Ä–æ–≤–µ—Ä–∫–∞: —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –ª–∏ —Ä—É—Å—Å–∫–∞—è –º–æ–¥–µ–ª—å spaCy
try:
    nlp = spacy.load("ru_core_news_md")
except OSError:
    raise RuntimeError(
        "–ù–µ —É—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞ –º–æ–¥–µ–ª—å 'ru_core_news_md' –¥–ª—è spaCy.\n"
        "–£—Å—Ç–∞–Ω–æ–≤–∏—Ç–µ –∫–æ–º–∞–Ω–¥–æ–π: python -m spacy download ru_core_news_md"
    )

###############################################################################
# –ü–µ—Ä–µ—á–∏—Å–ª–µ–Ω–∏–µ (Enum) –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π
###############################################################################
class Nationality(Enum):
    RUSSIAN = "–†—É—Å—Å–∫–∏–π"
    UKRAINIAN = "–£–∫—Ä–∞–∏–Ω–µ—Ü"
    BELARUSIAN = "–ë–µ–ª–æ—Ä—É—Å"
    UZBEK = "–£–∑–±–µ–∫"
    KAZAKH = "–ö–∞–∑–∞—Ö"
    GEORGIAN = "–ì—Ä—É–∑–∏–Ω"
    ARMENIAN = "–ê—Ä–º—è–Ω–∏–Ω"
    AZERBAIJANI = "–ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ—Ü"
    TAJIK = "–¢–∞–¥–∂–∏–∫"
    MOLDOVAN = "–ú–æ–ª–¥–∞–≤–∞–Ω–∏–Ω"
    LITHUANIAN = "–õ–∏—Ç–æ–≤–µ—Ü"
    LATVIAN = "–õ–∞—Ç—ã—à"
    ESTONIAN = "–≠—Å—Ç–æ–Ω–µ—Ü"
    TURKMEN = "–¢—É—Ä–∫–º–µ–Ω"
    KYRGYZ = "–ö–∏—Ä–≥–∏–∑"
    CHECHEN = "–ß–µ—á–µ–Ω–µ—Ü"
    DAGESTANI = "–î–∞–≥–µ—Å—Ç–∞–Ω–µ—Ü"
    INGUSH = "–ò–Ω–≥—É—à"
    TATAR = "–¢–∞—Ç–∞—Ä–∏–Ω"
    BURYAT = "–ë—É—Ä—è—Ç"
    ISLAM = "–ò—Å–ª–∞–º"
    CAUCASIAN = "–ö–∞–≤–∫–∞–∑"
    ASIAN = "–ê–∑–∏—è"
    ANGLO_SAXON = "–ê–Ω–≥–ª–æ—Å–∞–∫—Å"
    OSSETIAN = "–û—Å–µ—Ç–∏–Ω"
    AVAR = "–ê–≤–∞—Ä–µ—Ü"
    UNDETERMINED = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
    SHALAVY = "–®–∞–ª–∞–≤—ã"
    VULGAR = "VULGAR"

###############################################################################
# –≠–º–æ–¥–∂–∏-—Ñ–ª–∞–≥–∏ -> –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
###############################################################################
flag_emoji_nationality = {
    "üá∑üá∫": Nationality.RUSSIAN,
    "üá∫üá¶": Nationality.UKRAINIAN,
    "üáßüáæ": Nationality.BELARUSIAN,
    "üá∞üáø": Nationality.KAZAKH,
    "üá∫üáø": Nationality.UZBEK,
    "üáπüáØ": Nationality.TAJIK,
    "üá¨üá™": Nationality.GEORGIAN,
    "üá¶üá≤": Nationality.ARMENIAN,
    "üá¶üáø": Nationality.AZERBAIJANI,
    "üá≤üá©": Nationality.MOLDOVAN,
    "üá±üáπ": Nationality.LITHUANIAN,
    "üá±üáª": Nationality.LATVIAN,
    "üá™üá™": Nationality.ESTONIAN,
}

###############################################################################
# –°–ø–∏—Å–æ–∫ —Å—É—Ñ—Ñ–∏–∫—Å–æ–≤ –¥–ª—è —Ä–∞–∑–Ω—ã—Ö –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π
###############################################################################
suffixes = {
    Nationality.RUSSIAN: [
        "–æ–≤", "–µ–≤", "ov", "ev", "–∏–Ω", "in", "sky", "skiy", "ykh", "ikh",
        "–∏–π", "oy", "–æ–≤–∞", "–µ–≤–∞", "–∏–Ω–∞", "—Å–∫–∞—è"
    ],
    Nationality.UKRAINIAN: [
        "–µ–Ω–∫–æ", "enko", "—á—É–∫", "chuk", "–∫–æ", "ko", "—É–∫", "uk", "—é–∫", "yuk", "—ã–∫", "yk",
    ],
    Nationality.BELARUSIAN: [
        "–≤–∏—á", "vich", "–≤–∏—á—É—Å", "vichus", "–≤–∏—á–∏–∫", "vichyk"
    ],
    Nationality.KAZAKH: [
        "“±–ª—ã", "uly", "–∫—ã–∑—ã", "kyzy", "–±–µ–∫", "bek", "–±–∞–π", "bay", "—Ç–∞–π", "tai"
    ],
    Nationality.UZBEK: [
        "–∑–æ–¥–∞", "zoda", "–∑–∞–¥–µ", "zade", "zada", "zoda"
    ],
    Nationality.GEORGIAN: [
        "—à–≤–∏–ª–∏", "shvili", "–¥–∑–µ", "dze", "–∞–¥–∑–µ", "adze", "–∏—è", "ia", "—É—Ä–∏", "uri"
    ],
    Nationality.ARMENIAN: [
        "—è–Ω", "an", "—è–Ω—Ü", "yants"
    ],
    Nationality.AZERBAIJANI: [
        "–æ–≥–ª—ã", "ogly", "–∑–∞–¥–µ", "zade"
    ],
    Nationality.TAJIK: [
        "–∑–∞–¥–µ", "zade", "–∑–æ–¥–∞", "zoda"
    ],
    Nationality.MOLDOVAN: [
        "–∞—Ä—É", "aru", "–µ—Å–∫—É", "escu"
    ],
    Nationality.LITHUANIAN: [
        "–∞—Å", "as", "–∏—Å", "is", "—É—Å", "us", "—é—Å", "jus",
        "–∞–π—Ç–∏—Å", "aitis", "–π—Ç–µ", "ytƒó", "–µ–Ω–µ", "iene"
    ],
    Nationality.LATVIAN: [
        "–∞–Ω—Å", "ans", "–∫–∞–ª–Ω—Å", "kalns", "–≤–µ—Ü–º—É–∫—Ç–∞–Ω—Å",
        "vecmuktans", "—Å–æ–Ω—Å", "sons", "–±–µ—Ä–≥—Å", "bergs"
    ],
    Nationality.ESTONIAN: [
        "–º—è—ç", "m√§e", "–ø—ã–ª–¥", "p√µld", "–æ—è", "oja",
        "–≤—è–ª–∏", "v√§li", "–º—è–≥–∏", "m√§gi", "–º–µ—Ç—Å", "mets", "—Å–æ–æ", "soo"
    ],
    # –ü—Ä–∏–º–µ—Ä –¥–ª—è —Ç—É—Ä–∫–º–µ–Ω, –∫–∏—Ä–≥–∏–∑ –∏ —Ç.–¥. –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω—è—Ç—å.
}

def generate_transliterated_names_flatten(cyrillic_names):
    """ –°–æ–∑–¥–∞—ë–º —Å–ø–∏—Å–æ–∫, —Å–æ–¥–µ—Ä–∂–∞—â–∏–π –∏ –∫–∏—Ä–∏–ª–ª–∏—á–µ—Å–∫–∏–π, –∏ —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∏—Ä–æ–≤–∞–Ω–Ω—ã–π –≤–∞—Ä–∏–∞–Ω—Ç—ã. """
    flattened_list = []
    for name in cyrillic_names:
        flattened_list.append(name)
        transliterated = translit(name, 'ru', reversed=True)
        flattened_list.append(transliterated)
    return flattened_list

# –ü—Ä–∏–º–µ–Ω—è–µ–º —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—é –∫ —Å—É—Ñ—Ñ–∏–∫—Å–∞–º
for nat, names in suffixes.items():
    suffixes[nat] = generate_transliterated_names_flatten(names)

###############################################################################
# –ó–∞–≥—Ä—É–∑–∫–∞ typical_names.json, –µ—Å–ª–∏ —Å—É—â–µ—Å—Ç–≤—É–µ—Ç
###############################################################################
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
json_path = os.path.join(BASE_DIR, "json_data", "typical_names.json")
if os.path.exists(json_path):
    with open(json_path, "r", encoding="utf-8") as f:
        typical_names_data = json.load(f)
else:
    typical_names_data = {"typical_names": {}}

typical_names_json = typical_names_data.get("typical_names", {})
typical_names = {}

# –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ–º –∫–ª—é—á–∏ –≤ Enum, –µ—Å–ª–∏ –ø–æ–ª—É—á–∞–µ—Ç—Å—è
for key, value in typical_names_json.items():
    try:
        nat_enum = Nationality[key]
        typical_names[nat_enum] = value
    except KeyError:
        pass

###############################################################################
# –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º —É–º–µ–Ω—å—à–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—ã
###############################################################################
diminutive_names = {}
for nationality, names in typical_names.items():
    diminutives = []
    for name in names:
        doc = nlp(name)
        for token in doc:
            if token.pos_ == "PROPN":
                diminutive = token.text.lower() + "–∫–∞"  # –ü—Ä–∏–º–∏—Ç–∏–≤–Ω–∞—è —ç–≤—Ä–∏—Å—Ç–∏–∫–∞
                diminutives.append(diminutive)
    diminutive_names[nationality] = diminutives

# –û–±—ä–µ–¥–∏–Ω—è–µ–º –∏–º–µ–Ω–∞ –∏ —É–º–µ–Ω—å—à–∏—Ç–µ–ª—å–Ω—ã–µ + —Ç—Ä–∞–Ω—Å–ª–∏—Ç–µ—Ä–∞—Ü–∏—è
for nationality, names in typical_names.items():
    total_list = names + diminutive_names.get(nationality, [])
    typical_names[nationality] = generate_transliterated_names_flatten(total_list)

###############################################################################
# –õ–∞—Å–∫–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–∑–≤–∏—â–∞
###############################################################################
affectionate_nicknames = [
    "–ë—É—Å–∏–Ω–∫–∞", "–ó–∞–π—á–∏–∫", "–ö–æ—Ç–∏–∫", "–ú–∞–ª—ã—à", "–ú–∞–ª—ã—à–∫–∞", "–õ–∞—Å—Ç–æ—á–∫–∞", "–°–æ–ª–Ω—ã—à–∫–æ",
    "–ó–∞–π–∫–∞", "–ü—É–ø—Å–∏–∫", "–ó–∞–π—á–æ–Ω–æ–∫", "–ö–∏—Å–∫–∞", "–ú–∞—Å–∏–∫", "–ö—Ä–æ—à–∫–∞", "–†—ã–±–∫–∞", "–ö–æ—Ç—ë–Ω–æ–∫",
    "–ß–∞–ø–∞", "–í–∞—Å—å–∫–∞", "–°–µ–Ω—è", "–¢–æ—à–∞", "–ü–µ—Ç—å–∫–∞", "–õ—ë—à–∞"
]

def detect_nationality_from_affectionate_nickname(name: str):
    for nickname in affectionate_nicknames:
        if nickname.lower() in name.lower():
            return Nationality.RUSSIAN
    return None

###############################################################################
# –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã –≤ —Å–ª–æ–≤–µ -> –ø—Ä–∏–∑–Ω–∞–∫ —è–∑—ã–∫–∞
###############################################################################
def detect_nationality_from_letters(contact_name: str):
    # –£–∫—Ä–∞–∏–Ω—Å–∫–∏–µ –±—É–∫–≤—ã
    if re.search(r'[—ó—ñ—î“ë–Ü–á–Ñ“ê]', contact_name):
        return Nationality.UKRAINIAN
    # –ë–µ–ª–æ—Ä—É—Å—Å–∫–∏–µ –±—É–∫–≤—ã
    if re.search(r'[—û–é]', contact_name):
        return Nationality.BELARUSIAN
    # –ì—Ä—É–∑–∏–Ω—Å–∫–∏–π –∞–ª—Ñ–∞–≤–∏—Ç
    if re.search(r'[\u10A0-\u10FF]', contact_name):
        return Nationality.GEORGIAN
    # –ê—Ä–º—è–Ω—Å–∫–∏–π –∞–ª—Ñ–∞–≤–∏—Ç
    if re.search(r'[\u0530-\u058F]', contact_name):
        return Nationality.ARMENIAN
    # –ö–∞–∑–∞—Ö—Å–∫–∏–µ –±—É–∫–≤—ã
    kazakh_letters = '”ò”ô“í“ì“ö“õ“¢“£”®”©“∞“±“Æ“Ø“∫“ª–Ü—ñ'
    if re.search(f'[{kazakh_letters}]', contact_name):
        return Nationality.KAZAKH
    # –ò —Ç.–¥. –º–æ–∂–Ω–æ –¥–æ–ø–æ–ª–Ω—è—Ç—å
    return None

###############################################################################
# –ò—Å–ª–∞–º—Å–∫–∏–µ –∏–º–µ–Ω–∞ (–∑–∞–≥—Ä—É–∂–∞—é—Ç—Å—è –∏–∑ —Ñ–∞–π–ª–∞ islam_names.txt, –µ—Å–ª–∏ –µ—Å—Ç—å)
###############################################################################
islam_names_path = os.path.join(BASE_DIR, "islam_names.txt")
if os.path.exists(islam_names_path):
    with open(islam_names_path, "r", encoding="utf-8") as file:
        islamic_names = [line.strip() for line in file if line.strip()]
else:
    islamic_names = []

###############################################################################
# –ì–µ–æ-–∫–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ + —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏–µ —Å—Ç—Ä–∞–Ω–∞ -> –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
###############################################################################
geo_keywords = {
    "Russia": [
        "–ú–æ—Å–∫–≤–∞", "Moscow", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥",
        "–†–æ—Å—Ç–æ–≤-–Ω–∞-–î–æ–Ω—É", "–£—Ñ–∞", "–ö–∞–∑–∞–Ω—å", "–ù–∏–∂–Ω–∏–π –ù–æ–≤–≥–æ—Ä–æ–¥"
    ],
    "Ukraine": [
        "–ö–∏–µ–≤", "Kyiv", "–õ—å–≤–æ–≤", "Lviv", "–û–¥–µ—Å—Å–∞", "Odesa",
        "–•–∞—Ä—å–∫–æ–≤", "–•–µ—Ä—Å–æ–Ω", "–ó–∞–ø–æ—Ä–æ–∂—å–µ"
    ],
    "Belarus": [
        "–ú–∏–Ω—Å–∫", "Minsk", "–ì–æ–º–µ–ª—å", "–ë—Ä–µ—Å—Ç"
    ],
    "Kazakhstan": [
        "–ê–ª–º–∞—Ç—ã", "Almaty", "–ê—Å—Ç–∞–Ω–∞", "–ù—É—Ä-–°—É–ª—Ç–∞–Ω", "–®—ã–º–∫–µ–Ω—Ç", "–ö–∞—Ä–∞–≥–∞–Ω–¥–∞"
    ],
    "Uzbekistan": [
        "–¢–∞—à–∫–µ–Ω—Ç", "–°–∞–º–∞—Ä–∫–∞–Ω–¥", "–ë—É—Ö–∞—Ä–∞"
    ],
    "Georgia": [
        "–¢–±–∏–ª–∏—Å–∏", "–ë–∞—Ç—É–º–∏", "–ö—É—Ç–∞–∏—Å–∏", "–°—É—Ö—É–º–∏"
    ],
    "Armenia": [
        "–ï—Ä–µ–≤–∞–Ω", "–ì—é–º—Ä–∏", "–í–∞–Ω–∞–¥–∑–æ—Ä"
    ],
    "Azerbaijan": [
        "–ë–∞–∫—É", "Ganja", "–°—É–º–≥–∞–∏—Ç"
    ],
    "Moldova": [
        "–ö–∏—à–∏–Ω—ë–≤", "Chisinau", "–ë–µ–ª—å—Ü—ã"
    ],
    "Kyrgyzstan": [
        "–ë–∏—à–∫–µ–∫", "–û—à", "Jalal-Abad"
    ],
    "Tajikistan": [
        "–î—É—à–∞–Ω–±–µ", "–•—É–¥–∂–∞–Ω–¥", "–ö—É–ª—è–±"
    ],
    "Turkmenistan": [
        "–ê—à—Ö–∞–±–∞–¥", "Turkmenabat", "–ú–∞—Ä—ã"
    ],
    "Latvia": [
        "–†–∏–≥–∞", "–î–∞—É–≥–∞–≤–ø–∏–ª—Å", "–Æ—Ä–º–∞–ª–∞"
    ],
    "Lithuania": [
        "–í–∏–ª—å–Ω—é—Å", "–ö–∞—É–Ω–∞—Å", "–ö–ª–∞–π–ø–µ–¥–∞"
    ],
    "Estonia": [
        "–¢–∞–ª–ª–∏–Ω", "–¢–∞—Ä—Ç—É", "–ù–∞—Ä–≤–∞"
    ],
}
country_to_nationality = {
    "Russia": Nationality.RUSSIAN,
    "Ukraine": Nationality.UKRAINIAN,
    "Belarus": Nationality.BELARUSIAN,
    "Kazakhstan": Nationality.KAZAKH,
    "Uzbekistan": Nationality.UZBEK,
    "Georgia": Nationality.GEORGIAN,
    "Armenia": Nationality.ARMENIAN,
    "Azerbaijan": Nationality.AZERBAIJANI,
    "Moldova": Nationality.MOLDOVAN,
    "Kyrgyzstan": Nationality.KYRGYZ,
    "Tajikistan": Nationality.TAJIK,
    "Turkmenistan": Nationality.TURKMEN,
    "Latvia": Nationality.LATVIAN,
    "Lithuania": Nationality.LITHUANIAN,
    "Estonia": Nationality.ESTONIAN,
}

def detect_nationality_from_geo(contact_name: str):
    for country, cities in geo_keywords.items():
        for city in cities:
            if city.lower() in contact_name.lower():
                return country_to_nationality.get(country, Nationality.UNDETERMINED)
    return None

###############################################################################
# –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞ –∫–æ–º–ø–∞–Ω–∏–π -> –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
###############################################################################
company_keywords = {
    "Russia": ["–ì–∞–∑–ø—Ä–æ–º", "–°–±–µ—Ä–±–∞–Ω–∫", "–†–æ—Å–Ω–µ—Ñ—Ç—å", "–Ø–Ω–¥–µ–∫—Å", "–õ—É–∫–æ–π–ª"],
    "Ukraine": ["–ü—Ä–∏–≤–∞—Ç–ë–∞–Ω–∫", "–£–∫—Ä–ù–∞—Ñ—Ç–∞", "–†–æ—à–µ–Ω", "–ù–∞—Ñ—Ç–æ–≥–∞–∑"],
    "Kazakhstan": ["–ö–∞–∑–ú—É–Ω–∞–π–ì–∞–∑", "Halyk Bank", "–ö–∞–∑–ø–æ—á—Ç–∞"],
}

def detect_nationality_from_company(contact_name: str):
    for country, companies in company_keywords.items():
        for company in companies:
            if company.lower() in contact_name.lower():
                return country_to_nationality.get(country, Nationality.UNDETERMINED)
    return None

###############################################################################
# –ü—Ä–æ—Ñ–µ—Å—Å–∏–∏ / —Å–µ–º–µ–π–Ω—ã–µ —Å–≤—è–∑–∏ (–æ–ø—Ä–µ–¥–µ–ª—è–µ–º, —á—Ç–æ "—Ä—É—Å—Å–∫–∏–µ")
###############################################################################
family_relationships = [
    "–º–∞–º–∞", "–ø–∞–ø–∞", "–±—Ä–∞—Ç", "—Å–µ—Å—Ç—Ä–∞", "–¥—è–¥—è", "—Ç–µ—Ç—è", "–±–∞–±—É—à–∫–∞", "–¥–µ–¥—É—à–∫–∞",
    "—Å—ã–Ω", "–¥–æ—á—å", "–∫—É–º–∞", "–∫—É–º", "–∫—Ä–µ—Å—Ç–Ω—ã–π", "–∫—Ä–µ—Å—Ç–Ω–∞—è", "–±–∞—Ç—è", "—Å—É–ø—Ä—É–≥–∞",
    "–º—É–∂", "–∂–µ–Ω–∞", "–ª—é–±–∏–º—ã–π", "–ª—é–±–∏–º–∞—è", "–±—Ä–∞—Ç–∏—à–∫–∞", "—Å–µ—Å—Ç—Ä—ë–Ω–∫–∞", "–±–∞—Ç—é—à–∫–∞",
    "–º–∞—Ç—É—à–∫–∞", "–æ—Ç–µ—Ü", "–º–∞—Ç—å", "–¥—è–¥—å–∫–∞", "—Ç—ë—Ç—è", "–≤–Ω—É—á–∫–∞", "–≤–Ω—É–∫", "—Å–≤–µ–∫—Ä–æ–≤—å",
    "—Å–≤–µ–∫—Ä", "—Ç–µ—Å—Ç—å", "—Ç–µ—â–∞", "–∑—è—Ç—å", "–Ω–µ–≤–µ—Å—Ç–∫–∞", "–±—Ä–∞—Ç–∞–Ω", "—Å–µ—Å—Ç—Ä—É—Ö–∞",
    "–±–∞—Ç—è–Ω—è", "–±–∞–±—É–ª—è", "–¥–µ–¥—É–ª—è"
]
professions_and_relations = ["–±–∞—Ä–º–µ–Ω", "–≤—Ä–∞—á", "—É—á–∏—Ç–µ–ª—å", "—Ñ–µ—Ä–º–µ—Ä"]
professions_and_relations.extend(family_relationships)

def detect_nationality_from_profession_or_relation(contact_name: str):
    for word in professions_and_relations:
        if word.lower() in contact_name.lower():
            return Nationality.RUSSIAN
    return None

###############################################################################
# –£–º–µ–Ω—å—à–∏—Ç–µ–ª—å–Ω—ã–µ —Ñ–æ—Ä–º—ã
###############################################################################
diminutive_to_formal = {
    "–°–∞—à–∞": "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä",
    "–ö–æ–ª—è": "–ù–∏–∫–æ–ª–∞–π",
    "–í–∞–Ω—è": "–ò–≤–∞–Ω",
    "–î–∏–º–∞": "–î–º–∏—Ç—Ä–∏–π",
}

def normalize_diminutive(name: str):
    for diminutive, formal in diminutive_to_formal.items():
        if diminutive.lower() in name.lower():
            return name.lower().replace(diminutive.lower(), formal.lower())
    return name

###############################################################################
# –ì–ª–∞–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –ª—é–±–æ–º—É –∏–º–µ–Ω–∏
###############################################################################
def detect_nationality_from_name(name: str) -> Nationality:
    # 1. –£—á–∏—Ç—ã–≤–∞–µ–º —É–º–µ–Ω—å—à–∏—Ç–µ–ª—å–Ω—ã–µ
    name = normalize_diminutive(name)

    # 2. –õ–∞—Å–∫–∞—Ç–µ–ª—å–Ω—ã–µ –ø—Ä–æ–∑–≤–∏—â–∞
    aff_nat = detect_nationality_from_affectionate_nickname(name)
    if aff_nat:
        return aff_nat

    # 3. –§–ª–∞–≥-—ç–º–æ–¥–∂–∏
    for flag, nat_enum in flag_emoji_nationality.items():
        if flag in name:
            return nat_enum

    # 4. –°–ø–µ—Ü–∏—Ñ–∏—á–µ—Å–∫–∏–µ –±—É–∫–≤—ã
    letter_nat = detect_nationality_from_letters(name)
    if letter_nat:
        return letter_nat

    # 5. –¢–∏–ø–∏—á–Ω—ã–µ –∏–º–µ–Ω–∞
    name_parts = name.split()
    for nationality, nameset in typical_names.items():
        if any(part in nameset for part in name_parts):
            return nationality

    # 6. –ò—Å–ª–∞–º—Å–∫–∏–µ –∏–º–µ–Ω–∞
    if any(part in islamic_names for part in name_parts):
        return Nationality.ISLAM

    # 7. –°—É—Ñ—Ñ–∏–∫—Å—ã
    for nationality, suffix_list in suffixes.items():
        for suffix in suffix_list:
            if any(part.endswith(suffix) for part in name_parts):
                return nationality

    # 8. –ì–µ–æ
    geo_nat = detect_nationality_from_geo(name)
    if geo_nat:
        return geo_nat

    # 9. –ö–æ–º–ø–∞–Ω–∏–∏
    comp_nat = detect_nationality_from_company(name)
    if comp_nat:
        return comp_nat

    # 10. –ü—Ä–æ—Ñ–µ—Å—Å–∏–∏ / —Å–µ–º–µ–π–Ω—ã–µ —Å–≤—è–∑–∏
    prof_nat = detect_nationality_from_profession_or_relation(name)
    if prof_nat:
        return prof_nat

    return Nationality.UNDETERMINED

###############################################################################
# –û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–∏ –ø–æ –§–ò–û
###############################################################################
def detect_nationality_from_fio(fname: str, lname: str, mname: str) -> Nationality:
    full_name = " ".join(filter(None, [fname, lname, mname])).strip()
    if not full_name:
        return Nationality.UNDETERMINED
    return detect_nationality_from_name(full_name)

###############################################################################
# –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞
###############################################################################
def main():
    """
    –°—á–∏—Ç—ã–≤–∞–µ–º –¥–≤–∞ —Ñ–∞–π–ª–∞:
    1) CSV —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≥—Ä–∞–∂–¥–∞–Ω–∞—Ö (id, phone, FIO, –∞–¥—Ä–µ—Å –∏ —Ç.–¥.)
    2) alldata.txt (phone, user_id, –∫–∞–∫ –∑–∞–ø–∏—Å–∞–Ω, ...)

    –§–æ—Ä–º–∏—Ä—É–µ–º –≤—ã—Ö–æ–¥–Ω–æ–π CSV —Å –æ–±—ä–µ–¥–∏–Ω—ë–Ω–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–µ–π.
    """
    parser = argparse.ArgumentParser(
        description="–°–∫—Ä–∏–ø—Ç –¥–ª—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç–µ–π –ø–æ –¥–∞–Ω–Ω—ã–º –∏–∑ –¥–≤—É—Ö —Ñ–∞–π–ª–æ–≤."
    )
    # –í–∑–∞–∏–º–æ–∏—Å–∫–ª—é—á–∞—é—â–∏–µ —Ñ–ª–∞–≥–∏ -v/--verbose –∏ -s/--silent
    group = parser.add_mutually_exclusive_group(required=False)
    group.add_argument("-v", "--verbose", action="store_true",
                       help="–í—ã–≤–µ—Å—Ç–∏ –ø–æ–¥—Ä–æ–±–Ω—É—é –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –≤–æ –≤—Ä–µ–º—è —Ä–∞–±–æ—Ç—ã.")
    group.add_argument("-s", "--silent", action="store_true",
                       help="–ù–µ –≤—ã–≤–æ–¥–∏—Ç—å –Ω–∏–∫–∞–∫–æ–π –¥–æ–ø–æ–ª–Ω–∏—Ç–µ–ª—å–Ω–æ–π –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏–∏ (—Ç–∏—Ö–∏–π —Ä–µ–∂–∏–º).")

    parser.add_argument("-c", "--citizen-file", default="citizen_sample.csv",
                        help="–ü—É—Ç—å –∫ CSV-—Ñ–∞–π–ª—É —Å –¥–∞–Ω–Ω—ã–º–∏ –æ –≥—Ä–∞–∂–¥–∞–Ω–∞—Ö (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: citizen_sample.csv).")
    parser.add_argument("-a", "--alldata-file", default="alldata.txt",
                        help="–ü—É—Ç—å –∫ —Ñ–∞–π–ª—É alldata.txt (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: alldata.txt).")
    parser.add_argument("-o", "--output-file", default="output_result.csv",
                        help="–ü—É—Ç—å –∫ –≤—ã—Ö–æ–¥–Ω–æ–º—É CSV-—Ñ–∞–π–ª—É (–ø–æ —É–º–æ–ª—á–∞–Ω–∏—é: output_result.csv).")

    args = parser.parse_args()

    citizen_file = args.citizen_file
    alldata_file = args.alldata_file
    output_file = args.output_file
    is_verbose = args.verbose
    is_silent = args.silent

    # –ï—Å–ª–∏ –≤–∫–ª—é—á—ë–Ω verbose-—Ä–µ–∂–∏–º, –±—É–¥–µ–º –ø–µ—á–∞—Ç–∞—Ç—å —Å–æ–æ–±—â–µ–Ω–∏—è
    def log(message):
        if is_verbose and not is_silent:
            print(message)

    log(f"–§–∞–π–ª –≥—Ä–∞–∂–¥–∞–Ω: {citizen_file}")
    log(f"–§–∞–π–ª alldata: {alldata_file}")
    log(f"–í—ã—Ö–æ–¥–Ω–æ–π —Ñ–∞–π–ª: {output_file}")

    # --- 1) –°—á–∏—Ç—ã–≤–∞–µ–º —Ñ–∞–π–ª —Å –≥—Ä–∞–∂–¥–∞–Ω–∞–º–∏
    if not os.path.exists(citizen_file):
        print(f"–§–∞–π–ª {citizen_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        sys.exit(1)

    citizen_dict = {}
    with open(citizen_file, 'r', encoding='utf-8') as cf:
        reader = csv.DictReader(cf, delimiter=',')
        for row in reader:
            phone = row.get("phone", "").strip()
            if not phone or phone.lower() == "none":
                continue
            citizen_dict[phone] = {
                "id": row.get("id", ""),
                "fname": row.get("fname", "").strip(),
                "lname": row.get("lname", "").strip(),
                "mname": row.get("mname", "").strip(),
                "region": row.get("region", "").strip(),
                "city": row.get("city", "").strip(),
                "street": row.get("street", "").strip(),
                "house": row.get("house", "").strip(),
                "apr": row.get("apr", "").strip(),
                "country": row.get("country", "").strip()
            }

    log(f"–°—á–∏—Ç–∞–Ω–æ –≥—Ä–∞–∂–¥–∞–Ω: {len(citizen_dict)}")

    # --- 2) –°—á–∏—Ç—ã–≤–∞–µ–º alldata.txt
    if not os.path.exists(alldata_file):
        print(f"–§–∞–π–ª {alldata_file} –Ω–µ –Ω–∞–π–¥–µ–Ω!")
        sys.exit(1)

    results = []
    count = 0

    with open(alldata_file, 'r', encoding='utf-8') as adf:
        reader = csv.reader(adf, delimiter=',')
        for row in reader:
            if len(row) < 3:
                continue

            phone = row[0].strip()
            user_id = row[1].strip()
            how_recorded = row[2].strip()

            if phone.lower() == "none" or not phone:
                phone = None

            # –ù–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å –∏–∑ "–∫–∞–∫ –∑–∞–ø–∏—Å–∞–Ω" (2-–π –¥–æ–∫)
            nat_2nd_doc = detect_nationality_from_name(how_recorded)

            # –£–ø—Ä–æ—â—ë–Ω–Ω–∞—è –ª–æ–≥–∏–∫–∞ "–≥–µ–æ" –ø–æ –Ω–æ–º–µ—Ä—É —Ç–µ–ª–µ—Ñ–æ–Ω–∞ (–ø—Ä–µ—Ñ–∏–∫—Å—ã)
            phone_geo = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
            if phone:
                if phone.startswith("79") or phone.startswith("+79"):
                    phone_geo = "–†–æ—Å—Å–∏—è"
                elif phone.startswith("77") or phone.startswith("+77"):
                    phone_geo = "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω"
                elif phone.startswith("375") or phone.startswith("+375"):
                    phone_geo = "–ë–µ–ª–∞—Ä—É—Å—å"
                elif phone.startswith("380") or phone.startswith("+380"):
                    phone_geo = "–£–∫—Ä–∞–∏–Ω–∞"
                elif phone.startswith("998") or phone.startswith("+998"):
                    phone_geo = "–£–∑–±–µ–∫–∏—Å—Ç–∞–Ω"
                elif phone.startswith("994") or phone.startswith("+994"):
                    phone_geo = "–ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω"
                elif phone.startswith("995") or phone.startswith("+995"):
                    phone_geo = "–ì—Ä—É–∑–∏—è"
                elif phone.startswith("374") or phone.startswith("+374"):
                    phone_geo = "–ê—Ä–º–µ–Ω–∏—è"
                elif phone.startswith("996") or phone.startswith("+996"):
                    phone_geo = "–ö–∏—Ä–≥–∏–∑–∏—è"
                elif phone.startswith("992") or phone.startswith("+992"):
                    phone_geo = "–¢–∞–¥–∂–∏–∫–∏—Å—Ç–∞–Ω"
                elif phone.startswith("993") or phone.startswith("+993"):
                    phone_geo = "–¢—É—Ä–∫–º–µ–Ω–∏—Å—Ç–∞–Ω"
                # –ú–æ–∂–Ω–æ —Ä–∞—Å—à–∏—Ä—è—Ç—å –ø—Ä–∏ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ—Å—Ç–∏

            if phone and phone in citizen_dict:
                cdata = citizen_dict[phone]
                fio_nationality = detect_nationality_from_fio(
                    cdata["fname"], cdata["lname"], cdata["mname"]
                )
                # –ê–Ω–æ–Ω–∏–º–∏–∑–∞—Ü–∏—è –∞–¥—Ä–µ—Å–∞ (–¥–æ —É–ª–∏—Ü—ã)
                region = cdata["region"]
                city = cdata["city"]
                street = cdata["street"]
                address_anon = ", ".join(filter(None, [region, city, street]))

                fio_full = " ".join(filter(None, [cdata["fname"], cdata["lname"], cdata["mname"]]))

                row_out = [
                    user_id,
                    phone_geo,
                    nat_2nd_doc.value,  # –∏–∑ 2-–≥–æ –¥–æ–∫–∞
                    how_recorded,
                    address_anon,
                    fio_nationality.value,
                    fio_full
                ]
            else:
                # –ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –æ –≥—Ä–∞–∂–¥–∞–Ω–∏–Ω–µ –≤ 1-–º —Ñ–∞–π–ª–µ
                row_out = [
                    user_id,
                    phone_geo,
                    nat_2nd_doc.value,
                    how_recorded,
                    "",
                    "",
                    ""
                ]
            results.append(row_out)
            count += 1

    log(f"–û–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–æ–∫ alldata: {count}")

    # --- 3) –ó–∞–ø–∏—Å—ã–≤–∞–µ–º —Ä–µ–∑—É–ª—å—Ç–∞—Ç –≤ CSV
    with open(output_file, 'w', encoding='utf-8', newline='') as outf:
        writer = csv.writer(outf)
        writer.writerow([
            "ID_Telegram", "Geo_byPhone", "Nationality_2ndDoc",
            "HowRecorded", "Address_Anonymized",
            "Nationality_byFIO", "FIO"
        ])
        for row_out in results:
            writer.writerow(row_out)

    if not is_silent:
        print(f"–ì–æ—Ç–æ–≤–æ! –†–µ–∑—É–ª—å—Ç–∞—Ç —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {output_file}. –í—Å–µ–≥–æ —Å—Ç—Ä–æ–∫: {len(results)}.")

###############################################################################
# –¢–æ—á–∫–∞ –≤—Ö–æ–¥–∞
###############################################################################
if __name__ == "__main__":
    main()
