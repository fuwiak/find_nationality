import csv
import re
from enum import Enum
import spacy
from russiannames.parser import NamesParser
from transliterate import translit
from fuzzywuzzy import fuzz
import emoji  # Import emoji library to handle emojis

# Initialize the Russian NamesParser for ethnic classification
parser = NamesParser()

# Load the Russian language model from spaCy
nlp = spacy.load("ru_core_news_md")

# Enumeration for nationalities
class Nationality(Enum):
    RUSSIAN = "–†—É—Å—Å–∫–∏–π"
    UKRAINIAN = "–£–∫—Ä–∞–∏–Ω–µ—Ü"
    GEORGIAN = "–ì—Ä—É–∑–∏–Ω"
    ARMENIAN = "–ê—Ä–º—è–Ω–∏–Ω"
    AZERBAIJANI = "–ê–∑–µ—Ä–±–∞–π–¥–∂–∞–Ω–µ—Ü"
    KAZAKH = "–ö–∞–∑–∞—Ö"
    UZBEK = "–£–∑–±–µ–∫"
    TAJIK = "–¢–∞–¥–∂–∏–∫"
    BELARUSIAN = "–ë–µ–ª–æ—Ä—É—Å"
    MOLDOVAN = "–ú–æ–ª–¥–∞–≤–∞–Ω–∏–Ω"
    CHECHEN = "–ß–µ—á–µ–Ω–µ—Ü"
    DAGESTANI = "–î–∞–≥–µ—Å—Ç–∞–Ω–µ—Ü"
    CAUCASIAN = "–ö–∞–≤–∫–∞–∑"
    ASIAN = "–ê–∑–∏—è"
    ANGLO_SAXON = "–ê–Ω–≥–ª–æ—Å–∞–∫—Å"
    LATVIAN = "–õ–∞—Ç—ã—à"
    LITHUANIAN = "–õ–∏—Ç–æ–≤–µ—Ü"
    ESTONIAN = "–≠—Å—Ç–æ–Ω–µ—Ü"
    INGUSH = "–ò–Ω–≥—É—à"
    TATAR = "–¢–∞—Ç–∞—Ä–∏–Ω"
    BURYAT = "–ë—É—Ä—è—Ç"
    UNDETERMINED = "–ù–µ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–æ"
    SHALAVY = "–®–∞–ª–∞–≤—ã"
    VULGAR = "–®–∞–ª–æ–ø–∞–π"

# Dictionary mapping flag emojis to nationalities
flag_emoji_nationality = {
    "üá∑üá∫": Nationality.RUSSIAN,
    "üá∫üá¶": Nationality.UKRAINIAN,
    "üá¨üá™": Nationality.GEORGIAN,
    "üá¶üá≤": Nationality.ARMENIAN,
    "üá¶üáø": Nationality.AZERBAIJANI,
    "üá∞üáø": Nationality.KAZAKH,
    "üá∫üáø": Nationality.UZBEK,
    "üáπüáØ": Nationality.TAJIK,
    "üáßüáæ": Nationality.BELARUSIAN,
    "üá≤üá©": Nationality.MOLDOVAN,
    "üá±üáª": Nationality.LATVIAN,
    "üá±üáπ": Nationality.LITHUANIAN,
    "üá™üá™": Nationality.ESTONIAN,
}

# Suffixes dictionary
suffixes = {
    Nationality.RUSSIAN: ["–æ–≤", "–µ–≤", "ov", "ev", "–∏–Ω", "in", "sky", "skiy", "ykh", "ikh", "–∏–π", "oy", "–æ–≤–∞", "eva", "ina", "skaya"],
    Nationality.UKRAINIAN: ["–µ–Ω–∫–æ", "enko", "—á—É–∫", "chuk", "–∫–æ", "ko", "—É–∫", "uk", "—é–∫", "yuk", "—ã–∫", "yk"],
    Nationality.KAZAKH: ["“±–ª—ã", "uly", "–∫—ã–∑—ã", "kyzy", "–±–µ–∫", "bek", "–±–∞–π", "bay", "—Ç–∞–π", "tai"],
    Nationality.UZBEK: ["–∑–æ–¥–∞", "zoda", "–∑–∞–¥–µ", "zade", "zada", "zoda"],
    Nationality.BELARUSIAN: ["–≤–∏—á", "vich", "–≤–∏—á—É—Å", "vichus", "–≤–∏—á–∏–∫", "vichyk"],
    Nationality.MOLDOVAN: ["–∞—Ä—É", "aru", "–µ—Å–∫—É", "escu"],
    Nationality.CHECHEN: ["—Ö–∞–¥–∂", "khadzh", "—Ö–∞–¥–∂–∏", "khadzhi", "—Ö–æ–∂", "khozh", "—Ö–∞–¥–∂–∏–µ–≤", "khadzhiev"],
    Nationality.DAGESTANI: ["–≥–∞–¥–∂–∏–µ–≤", "gadzhiev", "—Ö–∞–¥–∂", "khadzh", "–≥–∞–¥–∂–∏", "gadji"],
    Nationality.CAUCASIAN: ["–ø—à", "psh", "—à–µ–≤", "shev"],
    Nationality.ASIAN: ["–±–µ–∫", "bek", "–±–∞–µ–≤", "baev", "–º–µ–¥–æ–≤", "medov", "–≥—É–ª–æ–≤", "gulov", "–∫—É–ª–æ–≤", "kulov", "–≥—É–ª", "gul"],
    Nationality.ANGLO_SAXON: ["—Å–æ–Ω", "son", "—Ç–æ–Ω", "ton", "–ª–µ–π", "ley", "—Ñ–æ—Ä–¥", "ford", "–≤—É–¥", "wood", "–º–∞–Ω", "man", "—Ñ–∏–ª–¥", "field", "–±—Ä—É–∫", "brook"],
    Nationality.LATVIAN: ["–∞–Ω—Å", "ans", "–∫–∞–ª–Ω—Å", "kalns", "–≤–µ—Ü–º—É–∫—Ç–∞–Ω—Å", "vecmuktans", "—Å–æ–Ω—Å", "sons", "–±–µ—Ä–≥—Å", "bergs"],
    Nationality.LITHUANIAN: ["–∞—Å", "as", "–∏—Å", "is", "—É—Å", "us", "—é—Å", "jus", "–∞–π—Ç–∏—Å", "aitis", "–π—Ç–µ", "ytƒó", "–µ–Ω–µ", "iene"],
    Nationality.ESTONIAN: ["–º—è—ç", "m√§e", "–ø—ã–ª–¥", "p√µld", "–æ—è", "oja", "–≤—è–ª–∏", "v√§li", "–º—è–≥–∏", "m√§gi", "–º–µ—Ç—Å", "mets", "—Å–æ–æ", "soo"],
    Nationality.INGUSH: ["–≥–æ–≤", "–≤–æ–≤", "–∏–≤", "–º–µ"],
    Nationality.TATAR: ["—É–ª–ª–∏–Ω", "–≥—É–ª–ª–∏–Ω", "—É–ª–ª–æ–≤", "—É–ª–æ–≤"],
    Nationality.BURYAT: ["–¥–æ—Ä–∂–∏–µ–≤", "–¥—É–≥–∞—Ä–æ–≤", "–±–∞–∏—Ä"],
}

def generate_transliterated_names_flatten(cyrillic_names):
    # Create a list that contains both Cyrillic and transliterated Latin versions
    flattened_list = []
    for name in cyrillic_names:
        flattened_list.append(name)  # Add Cyrillic name
        flattened_list.append(translit(name, 'ru', reversed=True))  # Add Latin name
    return flattened_list


# Apply the generate_transliterated_names_map function to all entries in raw_typical_names
suffixes = {nationality: generate_transliterated_names_flatten(names) for nationality, names in suffixes.items()}






# Add vulgar word detection
vulgar_words = ['–∏–¥–∏–æ—Ç', '–¥—É—Ä–∞–∫', '—à–∞–ª–∞–≤–∞', '—à–ª—é—Ö–∞', '–º—Ä–∞–∑—å', '—Å–≤–æ–ª–æ—á—å', '–ø–∏–¥–æ—Ä', '–ö–∞–∫–∞—à–∫–∞','–ö–∞–∫–∞—à–∫–∞üòÇ']

# Detect nationality based on vulgar words
def detect_vulgar_words(contact_name: str) -> Nationality:
    if any(vulgar_word in contact_name.lower() for vulgar_word in vulgar_words):
        return Nationality.VULGAR
    return None

# Detect nationality based on flag emoji
def detect_nationality_from_flag(contact_name: str) -> Nationality:
    for flag, nationality in flag_emoji_nationality.items():
        if flag in contact_name:
            return nationality
    return None

# Detect nationality based on geo-location keywords
geo_keywords = {
    "Russia": ["–ú–æ—Å–∫–≤–∞", "Moscow", "–°–∞–Ω–∫—Ç-–ü–µ—Ç–µ—Ä–±—É—Ä–≥", "Saint Petersburg", "–ù–æ–≤–æ—Å–∏–±–∏—Ä—Å–∫", "Novosibirsk", "–ï–∫–∞—Ç–µ—Ä–∏–Ω–±—É—Ä–≥", "Yekaterinburg"],
    "Ukraine": ["–ö–∏–µ–≤", "Kyiv", "–õ—å–≤–æ–≤", "Lviv", "–û–¥–µ—Å—Å–∞", "Odesa", "–î–Ω–µ–ø—Ä", "Dnipro", "–•–∞—Ä—å–∫–æ–≤", "Kharkiv"],
    "Georgia": ["–¢–±–∏–ª–∏—Å–∏", "Tbilisi", "–ë–∞—Ç—É–º–∏", "Batumi", "–ö—É—Ç–∞–∏—Å–∏", "Kutaisi", "–°—É—Ö—É–º–∏", "Sukhumi"],
    "Armenia": ["–ï—Ä–µ–≤–∞–Ω", "Yerevan", "–ì—é–º—Ä–∏", "Gyumri", "–í–∞–Ω–∞–¥–∑–æ—Ä", "Vanadzor"],
    "Azerbaijan": ["–ë–∞–∫—É", "Baku", "–ì—è–Ω–¥–∂–∞", "Ganja", "–°—É–º–≥–∞–∏—Ç", "Sumgait"],
    "Kazakhstan": ["–ù—É—Ä-–°—É–ª—Ç–∞–Ω", "Nur-Sultan", "–ê–ª–º–∞—Ç—ã", "Almaty", "–®—ã–º–∫–µ–Ω—Ç", "Shymkent", "–ö–∞—Ä–∞–≥–∞–Ω–¥–∞", "Karaganda"],
    "Uzbekistan": ["–¢–∞—à–∫–µ–Ω—Ç", "Tashkent", "–°–∞–º–∞—Ä–∫–∞–Ω–¥", "Samarkand", "–ë—É—Ö–∞—Ä–∞", "Bukhara"],
    "Tajikistan": ["–î—É—à–∞–Ω–±–µ", "Dushanbe", "–•—É–¥–∂–∞–Ω–¥", "Khujand", "–ö—É–ª—è–±", "Kulob"],
    "Belarus": ["–ú–∏–Ω—Å–∫", "Minsk", "–ì–æ–º–µ–ª—å", "Gomel", "–ú–æ–≥–∏–ª–µ–≤", "Mogilev", "–ë—Ä–µ—Å—Ç", "Brest"],
    "Latvia": ["–†–∏–≥–∞", "Riga", "–î–∞—É–≥–∞–≤–ø–∏–ª—Å", "Daugavpils", "–Æ—Ä–º–∞–ª–∞", "Jurmala"],
    "Lithuania": ["–í–∏–ª—å–Ω—é—Å", "Vilnius", "–ö–∞—É–Ω–∞—Å", "Kaunas", "–ö–ª–∞–π–ø–µ–¥–∞", "Klaipeda"],
    "Estonia": ["–¢–∞–ª–ª–∏–Ω", "Tallinn", "–¢–∞—Ä—Ç—É", "Tartu", "–ù–∞—Ä–≤–∞", "Narva"],
    "Chechnya": ["–ì—Ä–æ–∑–Ω—ã–π", "Grozny", "–®–∞–ª–∏", "Shali", "–ê—Ä–≥—É–Ω", "Argun"],
    "Dagestan": ["–ú–∞—Ö–∞—á–∫–∞–ª–∞", "Makhachkala", "–î–µ—Ä–±–µ–Ω—Ç", "Derbent", "–ö–∞—Å–ø–∏–π—Å–∫", "Kaspiysk"],
    "Ingushetia": ["–ù–∞–∑—Ä–∞–Ω—å", "Nazran", "–ú–∞–≥–∞—Å", "Magas"],
    "Tatarstan": ["–ö–∞–∑–∞–Ω—å", "Kazan", "–ù–∞–±–µ—Ä–µ–∂–Ω—ã–µ –ß–µ–ª–Ω—ã", "Naberezhnye Chelny", "–ê–ª—å–º–µ—Ç—å–µ–≤—Å–∫", "Almetyevsk"],
    "Buryatia": ["–£–ª–∞–Ω-–£–¥—ç", "Ulan-Ude", "–°–µ–≤–µ—Ä–æ–±–∞–π–∫–∞–ª—å—Å–∫", "Severobaykalsk", "–ì—É—Å–∏–Ω–æ–æ–∑—ë—Ä—Å–∫", "Gusinoozersk"],
    "Bashkortostan": ["–£—Ñ–∞", "Ufa", "–°—Ç–µ—Ä–ª–∏—Ç–∞–º–∞–∫", "Sterlitamak", "–°–∞–ª–∞–≤–∞—Ç", "Salavat"],
    "Komi": ["–°—ã–∫—Ç—ã–≤–∫–∞—Ä", "Syktyvkar", "–í–æ—Ä–∫—É—Ç–∞", "Vorkuta", "–£—Ö—Ç–∞", "Ukhta"],
    "Kalmykia": ["–≠–ª–∏—Å—Ç–∞", "Elista", "–õ–∞–≥–∞–Ω—å", "Lagan", "–ì–æ—Ä–æ–¥–æ–≤–∏–∫–æ–≤—Å–∫", "Gorodovikovsk"],
    "Karelia": ["–ü–µ—Ç—Ä–æ–∑–∞–≤–æ–¥—Å–∫", "Petrozavodsk", "–ö–æ–Ω–¥–æ–ø–æ–≥–∞", "Kondopoga", "–°–æ—Ä—Ç–∞–≤–∞–ª–∞", "Sortavala"],
    "Sakha (Yakutia)": ["–Ø–∫—É—Ç—Å–∫", "Yakutsk", "–ù–µ—Ä—é–Ω–≥—Ä–∏", "Neryungri", "–ú–∏—Ä–Ω—ã–π", "Mirny"],
}





def detect_nationality_from_geo(contact_name: str) -> Nationality:
    for country, locations in geo_keywords.items():
        for location in locations:
            if location.lower() in contact_name.lower():
                return country_to_nationality.get(country, None)
    return None

# Dictionary mapping countries/regions to nationalities
country_to_nationality = {
    "Russia": Nationality.RUSSIAN,
    "Ukraine": Nationality.UKRAINIAN,
    "Georgia": Nationality.GEORGIAN,
    "Armenia": Nationality.ARMENIAN,
    "Azerbaijan": Nationality.AZERBAIJANI,
    "Kazakhstan": Nationality.KAZAKH,
    "Uzbekistan": Nationality.UZBEK,
    "Tajikistan": Nationality.TAJIK,
    "Belarus": Nationality.BELARUSIAN,
    "Latvia": Nationality.LATVIAN,
    "Lithuania": Nationality.LITHUANIAN,
    "Estonia": Nationality.ESTONIAN,
    "Chechnya": Nationality.CHECHEN,
    "Dagestan": Nationality.DAGESTANI,
    "Ingushetia": Nationality.INGUSH,
    "Tatarstan": Nationality.TATAR,
    "Buryatia": Nationality.BURYAT,
    "Bashkortostan": Nationality.TATAR,  # –ú–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –∫–∞–∫ –¢–∞—Ç–∞—Ä—Å–∫—É—é –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å
    "Komi": Nationality.RUSSIAN,  # –í–æ–∑–º–æ–∂–Ω–∞ –∫–ª–∞—Å—Å–∏—Ñ–∏–∫–∞—Ü–∏—è –ø–æ —Ä—É—Å—Å–∫–æ–º—É –±–æ–ª—å—à–∏–Ω—Å—Ç–≤—É
    "Kalmykia": Nationality.RUSSIAN,  # –ú–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –ö–∞–ª–º—ã—Ü–∫—É—é –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    "Karelia": Nationality.RUSSIAN,  # –¢–∞–∫–∂–µ –º–æ–∂–Ω–æ –¥–æ–±–∞–≤–∏—Ç—å –∫–∞—Ä–µ–ª—å—Å–∫—É—é –Ω–∞—Ü–∏–æ–Ω–∞–ª—å–Ω–æ—Å—Ç—å, –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
    "Sakha (Yakutia)": Nationality.RUSSIAN,  # –ú–æ–∂–Ω–æ –∫–ª–∞—Å—Å–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞—Ç—å –∫–∞–∫ –Ø–∫—É—Ç—ã –∏–ª–∏ –æ—Å—Ç–∞–≤–∏—Ç—å —Ä—É—Å—Å–∫–∏–π
}



# Detect nationality based on patronymics
def detect_nationality_from_patronymic(patronymic: str) -> Nationality:
    for nationality, suffixes in patronymic_suffixes.items():
        if any(patronymic.lower().endswith(suffix.lower()) for suffix in suffixes):
            return nationality
    return None

# Detect nationality based on company names


company_names = ["Mitsubishi", "Toyota", "Gazprom", "Lukoil", "Samsung", "Honda", "Mitsubishi_tank",]  # Extend as needed



russian_banks_companies = [
    "–°–±–µ—Ä–±–∞–Ω–∫", "–¢–∏–Ω—å–∫–æ—Ñ—Ñ", "–í–¢–ë", "–ì–∞–∑–ø—Ä–æ–º–±–∞–Ω–∫", "–†–æ—Å–Ω–µ—Ñ—Ç—å", "–õ—É–∫–æ–π–ª", "–†–ñ–î", "–Ø–Ω–¥–µ–∫—Å",
    "–ú–∞–≥–Ω–∏—Ç", "–ú–¢–°", "–ú–µ–≥–∞—Ñ–æ–Ω", "–ë–∏–ª–∞–π–Ω", "–†–æ—Å—Ç–µ–ª–µ–∫–æ–º", "Mail.ru", "–û–∑–æ–Ω",
    "Wildberries", "–ü–æ—á—Ç–∞ –†–æ—Å—Å–∏–∏", "–ê—ç—Ä–æ—Ñ–ª–æ—Ç", "UTair", "S7 Airlines", "–®–∫–æ–ª–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∏—Ä–æ–≤–∞–Ω–∏—è", "–ö–æ–¥ –±—É–¥—É—â–µ–≥–æ",
    "–ü—è—Ç–µ—Ä–æ—á–∫–∞", "–ü–µ—Ä–µ–∫—Ä–µ—Å—Ç–æ–∫", "–ú.–í–∏–¥–µ–æ", "–≠–ª—å–¥–æ—Ä–∞–¥–æ", "–î–µ—Ç—Å–∫–∏–π –ú–∏—Ä", "–¢–∞–Ω—É–∫–∏", "–Ø–ø–æ—à–∞", "–†–æ—Å–≥–æ—Å—Å—Ç—Ä–∞—Ö",
    "–†–æ—Å–∞—Ç–æ–º", "–†–æ—Å–∫–æ—Å–º–æ—Å", "–†–æ—Å–º–æ—Ä–ø–æ—Ä—Ç", "–°—É—Ä–≥—É—Ç–Ω–µ—Ñ—Ç–µ–≥–∞–∑", "–ù–æ–≤–∞—Ç—ç–∫", "–ù–æ—Ä–Ω–∏–∫–µ–ª—å", "–ü–æ–ª—é—Å –ó–æ–ª–æ—Ç–æ",'–°–ø–∞—Ä—Ç–∞–∫–∞ –†–µ–º–æ–Ω—Ç'
]+company_names



def detect_nationality_from_company_names(contact_name: str) -> Nationality:
    for company in russian_banks_companies:
        if company.lower() in contact_name.lower():
            return Nationality.RUSSIAN
    return None

# Detect nationality based on professions and family relationships
professions = [
    '–≤–æ–µ–Ω–Ω—ã–π', '–∞–Ω–∏–º–∞—Ç–æ—Ä', '–±—É—Ö–≥–∞–ª—Ç–µ—Ä', '–∞–¥–≤–æ–∫–∞—Ç', '–≥–µ–Ω–µ—Ä–∞–ª', '–ø–æ–∂–∞—Ä–Ω—ã–π', '–¥–∏—Ä–µ–∫—Ç–æ—Ä',
    '–ø–∏–ª–æ—Ç', '–æ—Ñ–∏—Ü–∏–∞–Ω—Ç', '—ç–∫–æ–ª–æ–≥', '–º–µ—Ö–∞–Ω–∏–∫', '—Å—É–¥—å—è', '–ª–µ–π—Ç–µ–Ω–∞–Ω—Ç', '–≤–∏–¥–µ–æ–≥—Ä–∞—Ñ',
    '—à–∞—Ö—Ç–µ—Ä', '—Ñ–∞—Ä–º–∞—Ü–µ–≤—Ç', '–º–µ–Ω–µ–¥–∂–µ—Ä', '—ç–ª–µ–∫—Ç—Ä–∏–∫', '–ø—Ä–æ—Ñ–µ—Å—Å–æ—Ä', '–≤–æ–¥–∏—Ç–µ–ª—å',
    '—Å–≤–∞—Ä—â–∏–∫', '–±–∞—Ä–º–µ–Ω', '–∂—É—Ä–Ω–∞–ª–∏—Å—Ç', '—Ö–∏—Ä—É—Ä–≥', '—É—á—ë–Ω—ã–π', '–º–∞–π–æ—Ä', '–ø—Ä–æ–≤–∏–∑–æ—Ä',
    '–ø–æ–≤–∞—Ä', '–∞–≥—Ä–æ–Ω–æ–º', '—É—á–µ–Ω—ã–π', '–∏–Ω–∂–µ–Ω–µ—Ä', '—É—á–∞—Å–∫–æ–≤—ã–π', '—Å–∞–Ω—Ç–µ—Ö–Ω–∏–∫', '–ª—ë—Ç—á–∏–∫',
    '—Ä–µ–∫—Ä—É—Ç–µ—Ä', '–≤—Ä–∞—á', '–∞—Ä—Ö–∏—Ç–µ–∫—Ç–æ—Ä', '—Å–æ–ª–¥–∞—Ç', '–ª–æ–≥–∏—Å—Ç', '–ø—Ä–æ–≥—Ä–∞–º–º–∏—Å—Ç', '—Å—Ç—Ä–æ–∏—Ç–µ–ª—å',
    '—Ñ–æ—Ç–æ–≥—Ä–∞—Ñ', '–∑–∞–≤–æ–¥—Å–∫–æ–π —Ä–∞–±–æ—á–∏–π', '–±–∏–∑–Ω–µ—Å–º–µ–Ω', '–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥', '–ø–æ–ª–∫–æ–≤–Ω–∏–∫',
    '—É—á–∏—Ç–µ–ª—å–Ω–∏—Ü–∞', '–¥–æ–∫—Ç–æ—Ä', '–ø–æ–ª–∏—Ü–∏—è', '—é—Ä–∏—Å—Ç', '–º–µ–¥—Å–µ—Å—Ç—Ä–∞', '–¥–∏—Å–ø–µ—Ç—á–µ—Ä',
    '–¥–∏–∑–∞–π–Ω–µ—Ä', '–º—É–∑—ã–∫–∞–Ω—Ç', '–∫–∞–ø–∏—Ç–∞–Ω', '–ø—Å–∏—Ö–æ–ª–æ–≥', '–ª–µ—Ç—á–∏–∫', '–ø–∞—Ä–∏–∫–º–∞—Ö–µ—Ä', '—Ñ–µ–ª—å–¥—à–µ—Ä'
    '–¢–æ—á–∏—Ç –¶–µ–ø—å', '–ö–∞—Ç—Ä–∏–¥–∂'
]

family_relationships = [
    "–º–∞–º–∞", "–ø–∞–ø–∞", "–±—Ä–∞—Ç", "—Å–µ—Å—Ç—Ä–∞", "–¥—è–¥—è", "—Ç–µ—Ç—è", '–¢–µ—Ç—å','–¢—ë—Ç—å','–¢—è—Ç—å',"–±–∞–±—É—à–∫–∞",'–î—è—Ç—å', "–¥–µ–¥—É—à–∫–∞", "—Å—ã–Ω", "–¥–æ—á—å", "–∫—É–º–∞",
    "–∫—É–º", "–∫—Ä–µ—Å—Ç–Ω—ã–π", "–∫—Ä–µ—Å—Ç–Ω–∞—è", "–±–∞—Ç—è", "—Å—É–ø—Ä—É–≥–∞", "–º—É–∂", "–∂–µ–Ω–∞", "–ª—é–±–∏–º—ã–π", "–ª—é–±–∏–º–∞—è", "–±—Ä–∞—Ç–∏—à–∫–∞",
    "—Å–µ—Å—Ç—Ä—ë–Ω–∫–∞", "–±–∞—Ç—é—à–∫–∞", "–º–∞—Ç—É—à–∫–∞", "–æ—Ç–µ—Ü", "–º–∞—Ç—å", "–¥—è–¥—å–∫–∞", "—Ç—ë—Ç—è", "–≤–Ω—É—á–∫–∞", "–≤–Ω—É–∫", "—Å–≤–µ–∫—Ä–æ–≤—å",
    "—Å–≤–µ–∫—Ä", "—Ç–µ—Å—Ç—å", "—Ç–µ—â–∞", "–∑—è—Ç—å", "–Ω–µ–≤–µ—Å—Ç–∫–∞", "–±—Ä–∞—Ç–∞–Ω", "—Å–µ—Å—Ç—Ä—É—Ö–∞", "–±–∞—Ç—è–Ω—è", "–±–∞–±—É–ª—è", "–¥–µ–¥—É–ª—è"
]

def detect_nationality_from_professions_family(contact_name: str) -> Nationality:
    for word in professions + family_relationships:
        if word.lower() in contact_name.lower():
            return Nationality.RUSSIAN
    return None

# Detect nationality based on language-specific letters
def detect_nationality_from_letters(contact_name: str) -> Nationality:
    # Ukrainian-specific letters
    if re.search(r'[—ó—ñ—î“ë–Ü–á–Ñ“ê]', contact_name):
        return Nationality.UKRAINIAN

    # Belarusian-specific letters
    if re.search(r'[—û–é]', contact_name):
        return Nationality.BELARUSIAN

    # Georgian-specific letters
    if re.search(r'[\u10A0-\u10FF]', contact_name):  # Georgian script range
        return Nationality.GEORGIAN

    # Armenian-specific letters
    if re.search(r'[\u0530-\u058F]', contact_name):  # Armenian script range
        return Nationality.ARMENIAN

    # Kazakh-specific letters
    kazakh_letters = '”ò”ô“í“ì“ö“õ“¢“£”®”©“∞“±“Æ“Ø“∫“ª–Ü—ñ'
    if re.search(f'[{kazakh_letters}]', contact_name):
        return Nationality.KAZAKH

    # Add rules for other languages as needed
    return None

# Use NamesParser to detect ethnicity
def detect_ethnicity_using_parser(last_name: str, first_name: str, middle_name: str) -> Nationality:
    try:
        result = parser.classify(last_name, first_name, middle_name)
        ethnics = result.get("ethnics", [])
        if "kaz" in ethnics or "tur" in ethnics:
            return Nationality.KAZAKH
        elif "geo" in ethnics:
            return Nationality.GEORGIAN
        elif "arm" in ethnics:
            return Nationality.ARMENIAN
        elif "aze" in ethnics:
            return Nationality.AZERBAIJANI
        elif "che" in ethnics:
            return Nationality.CHECHEN
        elif "dag" in ethnics:
            return Nationality.DAGESTANI
        elif "ing" in ethnics:
            return Nationality.INGUSH
        elif "slav" in ethnics:
            return Nationality.RUSSIAN
    except Exception as e:
        return Nationality.UNDETERMINED
    return Nationality.UNDETERMINED

# Detect nationality based on typical first names
typical_names = {

    Nationality.RUSSIAN: [
        # Original names
        "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä", "–°–µ—Ä–≥–µ–π", "–î–º–∏—Ç—Ä–∏–π", "–ê–Ω–¥—Ä–µ–π", "–ê–ª–µ–∫—Å–µ–π", "–ú–∞–∫—Å–∏–º",
        "–ï–≤–≥–µ–Ω–∏–π", "–ò–≤–∞–Ω",
        "–ú–∏—Ö–∞–∏–ª", "–ù–∏–∫–æ–ª–∞–π", "–í–ª–∞–¥–∏–º–∏—Ä", "–ê—Ä—Ç–µ–º", "–î–µ–Ω–∏—Å", "–ü–∞–≤–µ–ª", "–ê–Ω—Ç–æ–Ω",
        "–í–∏–∫—Ç–æ—Ä",
        "–†–æ–º–∞–Ω", "–ò–≥–æ—Ä—å", "–ö–æ–Ω—Å—Ç–∞–Ω—Ç–∏–Ω", "–û–ª–µ–≥", "–í–∞—Å–∏–ª–∏–π", "–ö–∏—Ä–∏–ª–ª", "–Æ—Ä–∏–π",
        "–ò–ª—å—è",
        "–ü–µ—Ç—Ä", "–ù–∏–∫–∏—Ç–∞", "–ì—Ä–∏–≥–æ—Ä–∏–π", "–ë–æ—Ä–∏—Å", "–ì–µ–æ—Ä–≥–∏–π", "–ê–Ω–∞—Ç–æ–ª–∏–π", "–ó–∞—Ö–∞—Ä",
        "–¢–∞—Ç—å—è–Ω–∞", "–ï–ª–µ–Ω–∞", "–û–ª—å–≥–∞", "–ù–∞—Ç–∞–ª—å—è", "–ò—Ä–∏–Ω–∞", "–°–≤–µ—Ç–ª–∞–Ω–∞", "–ê–Ω–Ω–∞",
        "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞",
        "–ú–∞—Ä–∏—è", "–Æ–ª–∏—è", "–ê–Ω–∞—Å—Ç–∞—Å–∏—è", "–õ—é–¥–º–∏–ª–∞", "–ì–∞–ª–∏–Ω–∞", "–í–∞–ª–µ–Ω—Ç–∏–Ω–∞", "–ù–∏–Ω–∞",
        "–ú–∞—Ä–∏–Ω–∞",
        "–ù–∞–¥–µ–∂–¥–∞", "–õ—é–±–æ–≤—å", "–í–µ—Ä–∞", "–û–∫—Å–∞–Ω–∞", "–î–∞—Ä—å—è", "–ö—Å–µ–Ω–∏—è", "–ê–ª–∏–Ω–∞",
        "–ï–≤–≥–µ–Ω–∏—è",
        "–ê—Ä—Å–µ–Ω–∏–π", "–î–∞–Ω–∏–∏–ª", "–ï–≥–æ—Ä", "–ú–∞—Ç–≤–µ–π", "–¢–∏–º–æ—Ñ–µ–π", "–°—Ç–∞–Ω–∏—Å–ª–∞–≤",
        "–õ–µ–æ–Ω–∏–¥", "–í–∞–ª–µ—Ä–∏–π",
        "–í–∏—Ç–∞–ª–∏–π", "–í—è—á–µ—Å–ª–∞–≤", "–ì–ª–µ–±", "–ê—Ä—Ç—É—Ä", "–¢–∏–º—É—Ä", "–†—É—Å–ª–∞–Ω", "–í–ª–∞–¥–∏—Å–ª–∞–≤",
        "–°—Ç–µ–ø–∞–Ω",
        "–§–µ–¥–æ—Ä", "–°–µ–º–µ–Ω", "–ì–µ–Ω–Ω–∞–¥–∏–π", "–ê—Ä–∫–∞–¥–∏–π", "–õ–µ–≤", "–≠–¥—É–∞—Ä–¥", "–í–∞–ª–µ–Ω—Ç–∏–Ω",
        "–í–∞–¥–∏–º",
        "–°–æ—Ñ—å—è", "–ü–æ–ª–∏–Ω–∞", "–ú–∞—Ä–≥–∞—Ä–∏—Ç–∞", "–õ–∞—Ä–∏—Å–∞", "–ê–ª–ª–∞", "–ò–Ω–Ω–∞", "–Ø–Ω–∞",
        "–ö—Ä–∏—Å—Ç–∏–Ω–∞",
        "–í–∏–∫—Ç–æ—Ä–∏—è", "–õ–∏–¥–∏—è", "–ï–ª–∏–∑–∞–≤–µ—Ç–∞", "–î–∏–∞–Ω–∞", "–ö–∞—Ä–∏–Ω–∞", "–ñ–∞–Ω–Ω–∞", "–ó–æ—è",
        "–¢–∞–º–∞—Ä–∞",
        "–ê–ª–∏—Å–∞", "–í–∞—Ä–≤–∞—Ä–∞", "–ï–≤–¥–æ–∫–∏—è", "–ó–∏–Ω–∞–∏–¥–∞", "–ö–ª–∞–≤–¥–∏—è", "–†–∞–∏—Å–∞", "–£–ª—å—è–Ω–∞",
        "–≠–º–º–∞","–í–∏—Ç–∞–ª—è",
        # Diminutive and slang forms
        "–°–∞—à–∞", "–î–∏–º–∞", "–ú–∏—à–∞", "–ö–æ—Å—Ç—è", "–ö–æ–ª—è", "–í–∞–Ω—è", "–ü–∞—à–∞", "–ñ–µ–Ω—è",
        "–õ–µ—à–∞", "–ê–Ω–¥—Ä—é—à–∞",
        "–í–æ–≤–∞", "–ó–∞—Ö–∞—Ä–∫–∞", "–ö—Å—é—à–∞", "–ö—Å—é—Ö–∞", "–ú–∞—à–∞", "–î–∞—à–∞", "–ù–∞—Ç–∞—à–∞", "–ö–∞—Ç—è",
        "–ê–Ω—è",
        "–û–ª—è", "–°–≤–µ—Ç–∞", "–õ–µ–Ω–∞", "–ù–∞—Å—Ç—è", "–õ–∏–∑–∞", "–õ—é–±–∞", "–í–∏–∫–∞", "–ù–∏–∫–∞",
        "–°–µ—Ä–µ–∂–∞", "–ñ–æ—Ä–∞",
        "–Æ–ª—è", "–ì–µ–Ω–∞", "–¢–æ–ª–∏–∫", "–¢–æ—Ö–∞", "–ú–∞–∫—Å", "–ò–≥–æ—Ä–µ–∫", "–Ø—Ä–∏–∫", "–°–ª–∞–≤–∞",
        "–í–∏—Ç—è",
        "–ê—Ä—Ç–µ–º–∫–∞", "–°–ª–∞–≤–∏–∫", "–ñ–µ–Ω—å–∫–∞", "–õ–µ—Ö–∞", "–ì–æ—à–∞", "–°—Ç–∞—Å", "–õ–µ–≤–∞", "–õ—ë–≤–∞",
        "–õ–µ–≤—á–∏–∫",
        "–ú–∏—à–∞", "–ú–∏—à–∞–Ω—è", "–ú–∏—à–∫–∞", "–ê—Ä—Ç—ë–º", "–î–µ–Ω–∏—Å–∫–∞", "–ê–Ω—Ç–æ—Ö–∞", "–¢—ë–º–∞","–î–∞–Ω–∏–ª–ª","–î–∞–Ω–∏–ª","–í–æ–≤–∞–Ω","–¢–µ–º–∞","–õ√´–ª—è","–ê—Ä–∏–Ω–∞"
    ],

    Nationality.UKRAINIAN:[
    "–û–ª–µ–∫—Å–∞–Ω–¥—Ä", "–°–µ—Ä–≥—ñ–π", "–ê–Ω–¥—Ä—ñ–π", "–í–æ–ª–æ–¥–∏–º–∏—Ä", "–î–º–∏—Ç—Ä–æ", "–Ü–≤–∞–Ω", "–ú–∏–∫–æ–ª–∞", "–ú–∏—Ö–∞–π–ª–æ",
    "–ü–µ—Ç—Ä–æ", "–í–∞—Å–∏–ª—å", "–í—ñ–∫—Ç–æ—Ä", "–û–ª–µ–≥", "–Æ—Ä—ñ–π", "–ú–∞–∫—Å–∏–º", "–Ø—Ä–æ—Å–ª–∞–≤", "–Ñ–≤–≥–µ–Ω", "–¢–∞—Ä–∞—Å",
    "–ë–æ–≥–¥–∞–Ω", "–†–æ–º–∞–Ω", "–ê–Ω–∞—Ç–æ–ª—ñ–π", "–í–∞–ª–µ—Ä—ñ–π", "–ì—Ä–∏–≥–æ—Ä—ñ–π", "–î–µ–Ω–∏—Å", "–ü–∞–≤–ª–æ", "–†—É—Å–ª–∞–Ω",
    "–°—Ç–µ–ø–∞–Ω", "–Ü–≥–æ—Ä", "–õ–µ–æ–Ω—ñ–¥", "–ê—Ä—Ç–µ–º", "–í—ñ—Ç–∞–ª—ñ–π", "–û–ª–µ–∫—Å—ñ–π", "–ö–æ—Å—Ç—è–Ω—Ç–∏–Ω", "–ê–Ω—Ç–æ–Ω",
    "–í–∞–¥–∏–º", "–°—Ç–∞–Ω—ñ—Å–ª–∞–≤", "–ì–µ–Ω–Ω–∞–¥—ñ–π", "–ë–æ—Ä–∏—Å", "–í–ª–∞–¥–∏—Å–ª–∞–≤", "–í–∞–ª–µ–Ω—Ç–∏–Ω", "–ê—Ä—Ç—É—Ä",
    "–û–ª—å–≥–∞", "–¢–µ—Ç—è–Ω–∞", "–ù–∞—Ç–∞–ª—ñ—è", "–Ü—Ä–∏–Ω–∞", "–°–≤—ñ—Ç–ª–∞–Ω–∞", "–ú–∞—Ä—ñ—è", "–ö–∞—Ç–µ—Ä–∏–Ω–∞", "–ê–Ω–Ω–∞",
    "–Æ–ª—ñ—è", "–õ—é–¥–º–∏–ª–∞", "–û–∫—Å–∞–Ω–∞", "–ì–∞–ª–∏–Ω–∞", "–í–∞–ª–µ–Ω—Ç–∏–Ω–∞", "–õ–∞—Ä–∏—Å–∞", "–ù–∞–¥—ñ—è", "–í—ñ–∫—Ç–æ—Ä—ñ—è",
    "–õ—é–±–æ–≤", "–û–ª–µ–Ω–∞", "–õ—ñ–¥—ñ—è", "–ê–ª–ª–∞", "–Ü–Ω–Ω–∞", "–°–æ—Ñ—ñ—è", "–î–∞—Ä–∏–Ω–∞", "–•—Ä–∏—Å—Ç–∏–Ω–∞",
    "–û–ª–µ–∫—Å–∞–Ω–¥—Ä–∞", "–ú–∞—Ä–∏–Ω–∞", "–Ñ–≤–≥–µ–Ω—ñ—è", "–ó–æ—è", "–ñ–∞–Ω–Ω–∞", "–ê–ª–ª–∞", "–ü–æ–ª—ñ–Ω–∞", "–ú–∞—Ä–≥–∞—Ä–∏—Ç–∞",
    "–î–∞–Ω–∏–ª–æ", "–ù–∞–∑–∞—Ä", "–û—Å—Ç–∞–ø", "–ú–∞—Ç–≤—ñ–π", "–ó–∞—Ö–∞—Ä", "–¢–∏–º–æ—Ñ—ñ–π", "–ê—Ä—Å–µ–Ω", "–ì–ª—ñ–±",
    "–ö–∏—Ä–∏–ª–æ", "–§–µ–¥—ñ—Ä", "–°–µ–º–µ–Ω", "–ì–µ–æ—Ä–≥—ñ–π", "–ï–¥—É–∞—Ä–¥", "–ú–∞—Ä–∫", "–†–æ—Å—Ç–∏—Å–ª–∞–≤", "–°–≤—è—Ç–æ—Å–ª–∞–≤",
    "–ê–Ω–∞—Å—Ç–∞—Å—ñ—è", "–í–µ—Ä–æ–Ω—ñ–∫–∞", "–î—ñ–∞–Ω–∞", "–ê–ª—ñ–Ω–∞", "–Ø–Ω–∞", "–ö–∞—Ä–∏–Ω–∞", "–ê–Ω–≥–µ–ª—ñ–Ω–∞", "–û–ª–µ—Å—è",
    "–ú–∏—Ä–æ—Å–ª–∞–≤–∞", "–õ—ñ–ª—ñ—è", "–ù—ñ–Ω–∞", "–¢–∞–º–∞—Ä–∞", "–†–∞—ó—Å–∞", "–ó—ñ–Ω–∞—ó–¥–∞", "–ê–ª–ª–∞", "–£–ª—è–Ω–∞",
    "–ë–æ–∂–µ–Ω–∞", "–ó–ª–∞—Ç–∞", "–û—Ä–∏—Å—è", "–°–æ–ª–æ–º—ñ—è", "–õ–µ—Å—è", "–†–æ–∫—Å–æ–ª–∞–Ω–∞", "–ë–æ–≥–¥–∞–Ω–∞", "–ï–º–º–∞"
    ],



    Nationality.GEORGIAN: [
        "·Éí·Éò·Éù·É†·Éí·Éò", "–ì–µ–æ—Ä–≥–∏–π", "·Éú·Éò·Éú·Éù", "–ù–∏–Ω–æ", "·Éó·Éê·Éõ·Éê·É†", "–¢–∞–º–∞—Ä–∞", "·Éö·Éê·É®·Éê", "–õ–∞—à–∞",
        "·Éö·Éî·Éï·Éê·Éú", "–õ–µ–≤–∞–Ω", "·Éñ·É£·É†·Éê·Éë", "–ó—É—Ä–∞–±", "·Éõ·Éò·ÉÆ·Éî·Éò·Éö", "–ú–∏—Ö–∞–∏–ª", "·Éì·Éê·Éï·Éò·Éó", "–î–∞–≤–∏–¥",
        "·Éò·É†·Éê·Éô·Éö·Éò", "–ò—Ä–∞–∫–ª–∏–π", "·Éë·Éî·É°·Éù", "–ë–µ—Å–æ", "·Éõ·Éê·É†·Éò·Éê·Éõ", "–ú–∞—Ä–∏–∞–º", "·Éú·Éê·É¢·Éù", "–ù–∞—Ç–æ",
        "·Éó·Éî·Éù·Éú·Éê", "–¢–µ–æ–Ω–∞", "·É®·Éù·Éó·Éê", "–®–æ—Ç–∞", "·Éî·Éô·Éê", "–≠–∫–∞", "·Éí·É£·Éí·Éê", "–ì—É–≥–∞",
        "·Éî·Éö·Éî·Éú·Éî", "–≠–ª–µ–Ω–µ", "·Éô·Éê·ÉÆ·Éê", "–ö–∞—Ö–∞", "·Éó·Éî·Éõ·É£·É†", "–¢–µ–π–º—É—Ä", "·Éñ·Éï·Éò·Éê·Éì", "–ó–≤–∏–∞–¥"
    ],
    Nationality.ARMENIAN: [
        "‘±÷Ä’¥’•’∂", "–ê—Ä–º–µ–Ω", "’è’´’£÷Ä’°’∂", "–¢–∏–≥—Ä–∞–Ω", "’Ü’°÷Ä’•’Ø", "–ù–∞—Ä–µ–∫", "’Ä÷Ä’°’∂’ø",
        "–ì—Ä–∞–Ω—Ç", "‘≥’°’µ’°’∂’•", "–ì–∞—è–Ω—ç", "‘±’∂’°’∞’´’ø", "–ê–Ω–∞—Ö–∏—Ç", "‘±÷Ä’°", "–ê—Ä–∞", "’é’°÷Ä’§’°’∂",
        "–í–∞—Ä–¥–∞–Ω", "’ç’•÷Ä’™", "–°–µ—Ä–∂", "‘ø’°÷Ä’•’∂", "–ö–∞—Ä–µ–Ω", "’Ä’°’Ø’∏’¢", "–ê–∫–æ–±", "‘±÷Ä’ø’µ’∏’¥", "–ê—Ä—Ç—ë–º",
        "’ç’∏÷Ü’´’°", "–°–æ—Ñ–∏—è", "’Ñ’°÷Ä’´’°", "–ú–∞—Ä–∏—è", "‘º’•÷Ç’∏’∂", "–õ–µ–≤–æ–Ω", "’Ñ’°’∂’•", "–ú–∞–Ω–µ",
        "‘±’∂’∏÷Ç’∑", "–ê–Ω—É—à", "‘±÷Ä’¥’°’∂", "–ê—Ä–º–∞–Ω", "‘≥’∏’º", "–ì–æ—Ä", "’Ä’°’µ’Ø", "–ê–π–∫"
    ],
    Nationality.AZERBAIJANI: [
        "∆èli", "–ê–ª–∏", "M…ômm…ôd", "–ú–∞–º–µ–¥", "Murad", "–ú—É—Ä–∞–¥", "Leyla", "–õ–µ–π–ª–∞",
        "R…ô≈üad", "–†–∞—à–∞–¥", "Nigar", "–ù–∏–≥–∞—Ä", "∆èfqan", "–ê—Ñ–≥–∞–Ω", "Aysel", "–ê–π—Å–µ–ª—å",
        "Zaur", "–ó–∞—É—Ä", "Elvin", "–≠–ª—å–≤–∏–Ω", "G√ºlnar…ô", "–ì—é–ª—å–Ω–∞—Ä–∞", "Kamran", "–ö–∞–º—Ä–∞–Ω",
        "Cavid", "–î–∂–∞–≤–∏–¥", "Sevda", "–°–µ–≤–¥–∞", "Eldar", "–≠–ª—å–¥–∞—Ä", "Xanƒ±m", "–•–∞–Ω—ã–º",
        "S…ôbin…ô", "–°–∞–±–∏–Ω–∞", "F…ôrid", "–§–∞—Ä–∏–¥", "Zeyn…ôb", "–ó–µ–π–Ω–∞–±", "Fuad", "–§—É–∞–¥"
    ],
    Nationality.CHECHEN: [
        "–ê—Ö–º–∞–¥", "–ê—Ö–º–∞—Ç", "–†–∞–º–∑–∞–Ω", "–ó–µ–ª–∏–º—Ö–∞–Ω", "–ó–µ–ª–∏–º", "–ú–æ–≤–ª–∞–¥–∏", "–ò—Å–ª–∞–º",
        "–®–∞–º–∏–ª—å", "–ê–¥–∞–º", "–ú–∞–≥–æ–º–µ–¥", "–ú–æ–≤—Å–∞—Ä", "–õ–µ–º–∞"
    ],
    Nationality.DAGESTANI: [
        "–ú–∞–≥–æ–º–µ–¥", "–®–∞–º–∏–ª—å", "–ê–±–¥—É–ª–ª–∞", "–†–∞—Å—É–ª", "–ú—É—Ä–∞–¥", "–ì–∞–¥–∂–∏", "–†–∞—à–∏–¥",
        "–ê–±–¥—É–ª", "–£—Å–º–∞–Ω", "–•–∞–±–∏–±", "–ì–∞–º–∑–∞—Ç"
    ],
    Nationality.INGUSH: [
        "–Æ–Ω—É—Å-–ë–µ–∫", "–ú—É—Ä–∞—Ç", "–ú–∞–≥–æ–º–µ–¥", "–ú—É—Å–∞", "–ê–ª–∏", "–ë–µ—Å–ª–∞–Ω", "–ò—Å–∞",
        "–ú–∞–≥–æ–º–µ–¥-–ë–µ–∫"
    ],
    Nationality.UZBEK: [
        "–ê–∫—Ä–æ–º", "–£–ª—É“ì–±–µ–∫", "–ë–µ“≥–∑–æ–¥", "–ñ–∞–º—à–∏–¥", "–ê–ª–∏—à–µ—Ä", "–¢–µ–º—É—Ä", "–ë–æ–±—É—Ä",
        "–ò—Å–ª–æ–º", "–ú–∏—Ä–∑–æ", "–°–∞–∏–¥–∞–∫—Ä–∞–º", "–®–∞–≤–∫–∞—Ç", "–®—É—Ö—Ä–∞—Ç", "–®–µ—Ä–∑–æ–¥", "–ê–∑–∏–∑",
        "–ê–∫–º–∞–ª", "–§–∞—Ä—Ä—É—Ö"
    ],
    Nationality.KAZAKH: [
        "–ê—Å–µ–º", "–ö–∞–Ω–∞—Ç", "–ù—É—Ä—Å—É–ª—Ç–∞–Ω", "–ë–∞–∫—ã—Ç", "–ñ–∞–Ω–Ω–∞", "–ê–π–≥–µ—Ä–∏–º", "–î–∞–Ω–∏—è—Ä",
        "–ê–ª–º–∞–∑", "–ê–π—Å—É–ª—É", "–ï—Ä–∂–∞–Ω", "–ë–∞–≥–¥–∞—Ç", "–ì—É–ª—å–∂–∞–Ω", "–ú–∞–¥–∏–Ω–∞", "–°–µ—Ä–∏–∫",
        "–ê–ª–∏—è", "–ë–∞—Ö—ã—Ç", "–ñ–∞–Ω–∞—Ä"
    ],

    Nationality.TATAR: [
        "–†–∏–Ω–∞—Ç", "–§–∞—Ä–∏—Ç", "–ò–ª—å–¥–∞—Ä", "–†–∞–º–∏–ª—å", "–†—É—à–∞–Ω", "–ì—É–ª—å–Ω–∞—Ä–∞", "–ú–∞—Ä–∞—Ç", "–†–∞—Ñ–∏—Å","–î–∞–º–∏—Ä", "Damir"
    ]
}


typical_names = {nationality: generate_transliterated_names_flatten(names) for nationality, names in typical_names.items()}



# Suffixes for patronymics
patronymic_suffixes = {
    Nationality.RUSSIAN: ["–æ–≤–∏—á", "–µ–≤–∏—á", "–æ–≤–Ω–∞", "–µ–≤–Ω–∞"],
    Nationality.UKRAINIAN: ["–æ–≤–∏—á", "–µ–≤–∏—á", "–æ–≤–Ω–∞", "–µ–≤–Ω–∞", "—ñ–≤–∏—á", "—ñ—ó–≤–Ω–∞"],
    Nationality.BELARUSIAN: ["–æ–≤–∏—á", "–µ–≤–∏—á", "–æ–≤–Ω–∞", "–µ–≤–Ω–∞", "–æ–≤—ñ—á", "–µ–≤—ñ—á"],
    Nationality.GEORGIAN: ["—à–≤–∏–ª–∏", "–¥–∑–µ"],
    Nationality.ARMENIAN: ["—è–Ω", "—è–Ω—Ü"],
    Nationality.AZERBAIJANI: ["–æ–≥–ª—ã", "–∫—ã–∑—ã"],
    Nationality.KAZAKH: ["—É–ª—ã", "–∫—ã–∑—ã"],
    Nationality.UZBEK: ["–∑–æ–¥–∞", "–∑–∞–¥–µ", "zada"],
    Nationality.TAJIK: ["–∑–æ–¥–∞", "–∑–∞–¥–µ", "zada"],
}


# List of affectionate nicknames (in Russian)
affectionate_nicknames = [
    "–ë—É—Å–∏–Ω–∫–∞", "–ó–∞–π—á–∏–∫", "–ö–æ—Ç–∏–∫", "–ú–∞–ª—ã—à", "–ú–∞–ª—ã—à–∫–∞", "–õ–∞—Å—Ç–æ—á–∫–∞", "–°–æ–ª–Ω—ã—à–∫–æ",
    "–ó–∞–π–∫–∞", "–ü—É–ø—Å–∏–∫", "–ó–∞–π—á–æ–Ω–æ–∫", "–ö–∏—Å–∫–∞", "–ú–∞—Å–∏–∫", "–ö—Ä–æ—à–∫–∞", "–†—ã–±–∫–∞", "–ö–æ—Ç—ë–Ω–æ–∫",
    "–ß–∞–ø–∞", "–í–∞—Å—å–∫–∞", "–°–µ–Ω—è", "–¢–æ—à–∞", "–ü–µ—Ç—å–∫–∞", "–õ—ë—à–∞"
]

def detect_nationality_from_affectionate_nickname(name: str) -> Nationality:
    # Check if the name contains any affectionate nickname
    for nickname in affectionate_nicknames:
        if nickname.lower() in name.lower():
            return Nationality.RUSSIAN
    return None



ranks = ["–†—è–¥–æ–≤–æ–π", "–°–µ—Ä–∂–∞–Ω—Ç", "–õ–µ–π—Ç–µ–Ω–∞–Ω—Ç", "–ö–∞–ø–∏—Ç–∞–Ω", "–ì–µ–Ω–µ—Ä–∞–ª", "–ü–æ–ª–∫–æ–≤–Ω–∏–∫"]

# Additional handling for diminutives and non-name parts
diminutive_to_formal = {
    "–°–∞–Ω—è": "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä",  # Example: map diminutive to formal names
    "–°–∞—à–∞": "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä",
    "–í–∞–Ω—è": "–ò–≤–∞–Ω",
    "–ö–æ–ª—è": "–ù–∏–∫–æ–ª–∞–π"
}

# Add common non-name parts to ignore
non_name_parts = ["–†–µ–º–æ–Ω—Ç", "–¢–∞–Ω–∫", "–ê–≤—Ç–æ", "–ú–∏—Ç—Å—É–±–∏—Å–∏", "–°–ø–∞—Ä—Ç–∞–∫–∞", "–†—è–¥–æ–≤–æ–π"]


# Initialize an empty list to store all Islamic names
islam_names = []

# Load the islamic names from a text file
with open("islam_names.txt", "r", encoding="utf-8") as file:
    for line in file:
        line = line.strip()
        if line and not line.startswith("---"):
            islam_names.append(line)

def is_non_name_part(part: str) -> bool:
    """Check if a part of the name is a non-name element like business or service."""
    return any(non_name.lower() in part.lower() for non_name in non_name_parts)

# Handle diminutives mapping to formal names
def normalize_diminutive(name: str) -> str:
    """Replace diminutive forms with their formal names."""
    return diminutive_to_formal.get(name, name)  # Return formal name if found, otherwise return as is




def detect_nationality_from_first_name(name_parts) -> Nationality:
    first_name = name_parts[0] if name_parts else ""

    # Loop through the typical names dictionary
    for nationality, names in typical_names.items():
        # Iterate over pairs of (Cyrillic, Latin) names
        for i in range(0, len(names), 2):
            cyrillic_name = names[i]
            latin_name = names[i + 1]
            # Check if the first name matches either the Cyrillic or the Latin version
            if first_name.lower() == cyrillic_name.lower() or first_name.lower() == latin_name.lower():
                return nationality

    return None


# Match nationality based on name parts
def match_nationality(name_parts):
    first_name = name_parts[0] if len(name_parts) > 0 else ""
    last_name = name_parts[-1] if len(name_parts) > 1 else ""
    middle_name = name_parts[1] if len(name_parts) == 3 else ""

    # Ethnic classification using NamesParser
    if len(name_parts) >= 2:
        ethnicity_nationality = detect_ethnicity_using_parser(last_name, first_name, middle_name)
        if ethnicity_nationality != Nationality.UNDETERMINED:
            return ethnicity_nationality

    # Check for nationality based on typical first names
    name_nationality = detect_nationality_from_first_name(name_parts)
    if name_nationality:
        return name_nationality

    # Use suffix matching if ethnicity and name are not determined
    matches = {nationality: 0 for nationality in suffixes}
    for part in name_parts:
        for nationality, suff in suffixes.items():
            if any(part.lower().endswith(suffix) for suffix in suff):
                matches[nationality] += 1

    selected_nationality = max(matches, key=matches.get)
    return selected_nationality if matches[selected_nationality] > 0 else Nationality.UNDETERMINED


# Function to remove emojis and special characters
def clean_name(name: str) -> str:
    # Use regex to remove all emojis and special characters
    name_cleaned = re.sub(r'[^\w\s]', '', name)  # Keep only word characters and spaces
    name_cleaned = re.sub(r'\d', '', name_cleaned)  # Optionally, remove numbers if needed
    return name_cleaned.strip()  # Remove leading and trailing whitespace

# Detect nationality based on name
# Updated nationality detection function
def detect_nationality_from_name(name: str) -> Nationality:
    # Step 1: Check for flag emoji indicating nationality
    flag_nationality = detect_nationality_from_flag(name)
    if flag_nationality:
        return flag_nationality

    # Step 2: Clean the name by removing non-flag emojis and special characters
    cleaned_name = clean_name(name)

    # Split the cleaned name into parts
    name_parts = cleaned_name.split()

    # Step 3: Normalize diminutives to formal names
    name_parts = [normalize_diminutive(part) for part in name_parts]

    # Step 4: Filter out non-name parts (like "–†–µ–º–æ–Ω—Ç", "–¢–∞–Ω–∫", etc.)
    name_parts = [part for part in name_parts if not is_non_name_part(part)]

    # Step 5: Handle first name detection (e.g., "Damir")
    first_name_nationality = detect_nationality_from_first_name(name_parts)
    if first_name_nationality:
        return first_name_nationality

    # Step Check for affectionate nickname
    affectionate_nickname_nationality = detect_nationality_from_affectionate_nickname(
        cleaned_name)
    if affectionate_nickname_nationality:
        return affectionate_nickname_nationality

    # Step 6: Check for vulgar words in the cleaned name
    vulgar_nationality = detect_vulgar_words(cleaned_name)
    if vulgar_nationality:
        return vulgar_nationality

    # Step 7: Check for special 'üí¶' marker for specific classification
    if 'üí¶' in name:
        return Nationality.SHALAVY

    # Step 8: Check for geo-related data in the cleaned name (e.g., locations, countries)
    geo_nationality = detect_nationality_from_geo(cleaned_name)
    if geo_nationality:
        return geo_nationality

    # Step 9: Check for company names indicating nationality
    company_nationality = detect_nationality_from_company_names(cleaned_name)
    if company_nationality:
        return company_nationality

    # Step 10: Check for profession or family relationships
    prof_rel_nationality = detect_nationality_from_professions_family(cleaned_name)
    if prof_rel_nationality:
        # If family relationship is found, still check if first name overrides it
        if first_name_nationality:
            return first_name_nationality
        return prof_rel_nationality

    # Step 11: Check for patronymic-based detection (in the case of full names)
    if len(name_parts) == 3:
        patronymic = name_parts[2]
        patronymic_nationality = detect_nationality_from_patronymic(patronymic)
        if patronymic_nationality:
            return patronymic_nationality

    # Step 12: Check for language-specific letters indicating nationality
    letter_nationality = detect_nationality_from_letters(cleaned_name)
    if letter_nationality:
        return letter_nationality

    # Step 13: Use existing surname detection logic to match the nationality
    return match_nationality(cleaned_name.split())




# Function to extract country code from phone number
def extract_country_code(phone_number, country_codes):
    # Remove '+' or '00' from the beginning
    if phone_number.startswith('+'):
        phone_number = phone_number[1:]
    elif phone_number.startswith('00'):
        phone_number = phone_number[2:]
    # Try to find the longest matching country code
    for code in country_codes:
        if phone_number.startswith(code):
            return code, phone_number[len(code):]
    # If no country code found, return None
    return None, phone_number

# Function to read mobile patterns from CSV file
def read_patterns_from_csv(csv_filename):
    pattern_regions = []
    with open(csv_filename, 'r', encoding='utf-8') as csvfile:
        reader = csv.reader(csvfile)
        next(reader)  # Skip the header row
        for row in reader:
            if len(row) != 4:
                continue  # Skip rows that don't have exactly 4 columns
            code, number_pattern, operator, region = row
            code = code.strip()
            number_pattern = number_pattern.strip()
            operator = operator.strip()
            region = region.strip()

            # Remove 'code-' prefix from number_pattern if present
            if number_pattern.startswith(code + '-'):
                number_pattern = number_pattern[len(code) + 1:]
            # Combine code and number_pattern to get full pattern
            full_pattern = code + number_pattern

            # Replace 'x' with '\d' in regex
            regex_pattern = '^' + full_pattern.replace('x', r'\d') + '$'

            # Compile the regex
            regex = re.compile(regex_pattern)

            # Append to the list
            pattern_regions.append((regex, region))
    return pattern_regions

# Function to read CIS landline and mobile patterns from CSV file
def read_patterns_cis(csv_filename):
    patterns_cis = []
    country_codes_set = set()
    country_code_to_name = {}
    with open(csv_filename, 'r', encoding='utf-8') as csvfile:
        reader = csv.reader(csvfile)
        next(reader)  # Skip header
        for row in reader:
            if len(row) != 4:
                continue  # Skip invalid rows
            country, country_code, city_code, city = row
            country = country.strip()
            country_code = country_code.strip()
            city_code = city_code.strip()
            city = city.strip()
            country_codes_set.add(country_code)
            country_code_to_name[country_code] = country  # Map country code to country name
            # Construct a pattern for the remaining number after country code
            pattern = '^' + city_code + r'\d+$'  # Accept any number of digits after city code
            regex = re.compile(pattern)
            patterns_cis.append((regex, country_code, city))
    # Build ordered list of country codes by length descending
    country_codes = sorted(country_codes_set, key=lambda x: -len(x))
    return patterns_cis, country_codes, country_code_to_name

# Function to read contacts from alldata.txt
def read_contacts(filename, limit=None):
    contacts = []
    with open(filename, 'r', encoding='utf-8') as f:
        for idx, line in enumerate(f):
            if limit and idx >= limit:
                break
            line = line.strip()
            if not line:
                continue  # Skip empty lines
            parts = line.split(',')
            if len(parts) >= 3:
                phone_number = parts[0].strip().strip('"')
                contact_name = parts[2].strip().strip('"')
                contacts.append((phone_number, contact_name))
    return contacts

# Function to determine the region and nationality of a contact
def process_contact(phone_number, contact_name, pattern_regions, patterns_cis, country_codes, country_code_to_name):
    original_phone_number = phone_number
    if not phone_number or phone_number.lower() == 'none':
        region = "No region found"
        country = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∞"
    else:
        phone_number = phone_number.strip()
        # Remove any '+' or '00' from the beginning
        if phone_number.startswith('+'):
            phone_number = phone_number[1:]
        elif phone_number.startswith('00'):
            phone_number = phone_number[2:]
        # Handling Kazakhstan numbers
        if phone_number.startswith('77'):
            # Kazakhstan mobile numbers
            region = "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω"
            country = "–ö–∞–∑–∞—Ö—Å—Ç–∞–Ω"
        elif phone_number.startswith('7'):
            # Russian numbers
            mobile_number = phone_number[1:]  # Remove '7'
            region_found = False
            for regex, region_match in pattern_regions:
                if regex.match(mobile_number):
                    region = f"–†–æ—Å—Å–∏—è, {region_match}"
                    region_found = True
                    break
            if not region_found:
                region = "–†–æ—Å—Å–∏—è, –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π —Ä–µ–≥–∏–æ–Ω"
            country = "–†–æ—Å—Å–∏—è"
        else:
            # Try to extract country code
            country_code, remaining_number = extract_country_code(phone_number, country_codes)
            if country_code:
                # Try to match the remaining number with patterns_cis
                region = "No region found"
                for regex, pattern_country_code, city in patterns_cis:
                    if country_code == pattern_country_code and regex.match(remaining_number):
                        country = country_code_to_name.get(country_code, "Unknown country")
                        region = f"{country}, {city}"
                        break
                if region == "No region found":
                    country = country_code_to_name.get(country_code, "Unknown country")
                    region = f"{country}, –ù–µ–∏–∑–≤–µ—Å—Ç–Ω—ã–π –≥–æ—Ä–æ–¥"
            else:
                region = "No region found"
                country = "–ù–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è —Å—Ç—Ä–∞–Ω–∞"

    # Detect nationality from contact name
    if contact_name:
        nationality = detect_nationality_from_name(contact_name)
    else:
        nationality = Nationality.UNDETERMINED

    # If nationality is still undetermined, and country is known, set nationality based on country
    if nationality == Nationality.UNDETERMINED and country in country_to_nationality:
        nationality = country_to_nationality[country]

    return {
        "phone_number": original_phone_number,
        "contact_name": contact_name,
        "region": region,
        "nationality": nationality.value if isinstance(nationality, Nationality) else nationality
    }

def main():
    # Read mobile patterns from mobile_codes.csv
    pattern_regions = read_patterns_from_csv('mobile_codes.csv')

    # Read CIS landline and mobile patterns from city_codes_cis.csv
    patterns_cis, country_codes, country_code_to_name = read_patterns_cis('city_codes_cis.csv')

    # Read contacts from alldata.txt (processing top entries)
    contacts = read_contacts('alldata.txt', limit=1000)

    # Open a CSV file to save the results
    with open('output_results.csv', mode='w', newline='', encoding='utf-8') as file:
        writer = csv.writer(file)
        # Write the header
        writer.writerow(['Phone Number', 'Region', 'contact_name', 'Nationality'])

        # Process each contact and save the region and nationality
        for phone_number, contact_name in contacts:
            result = process_contact(phone_number, contact_name, pattern_regions, patterns_cis, country_codes, country_code_to_name)
            output_line = [result['phone_number'], result['region'], result['contact_name'], result['nationality']]
            writer.writerow(output_line)

if __name__ == '__main__':
    main()